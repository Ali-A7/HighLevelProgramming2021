{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named \"data_int.txt\". Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named \"data_float.txt\". Use the `cat` command to print the content of the file.\n",
    "+ load the txt file of the previous point and convert it to a csv file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "#create a list of integrer numbers\n",
    "file_name = \"./data_int.txt\"\n",
    "lst = [i for i in range(20)]\n",
    "\n",
    "with open(\"data_int.txt\", \"w\") as f:\n",
    "    f.write(str(lst))\n",
    "    \n",
    "with open(\"data_int.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "!type data_int.txt\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24 0.02 0.50 0.58 0.91\n",
      "0.32 0.87 0.82 0.55 0.99\n",
      "0.44 0.01 0.36 0.80 0.09\n",
      "0.94 0.22 0.19 0.12 0.73\n",
      "0.02 0.00 0.30 0.88 0.65\n"
     ]
    }
   ],
   "source": [
    "#create a matrix of 5x5 floats \n",
    "import numpy as np\n",
    "file_name = \"./data_float.txt\"\n",
    "x = np.random.random((5,5))\n",
    "matrix = np.matrix(x)\n",
    "with open('data_float.txt','wb') as f:\n",
    "    for line in matrix:\n",
    "        np.savetxt(f, line, fmt='%.2f')\n",
    "!type \"data_float.txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,Investment  Advisor,Clint_Thorpe5003@bulaffy.com,Clint Thorpe,7083-8766-0251-2345,American Express\n",
      "12,Retail Trainee,Phillip_Carpenter9505@famism.biz,Phillip Carpenter,3657-0088-0820-5247,American Express\n",
      "28,Project Manager,Russel_Graves1378@extex.org,Russel Graves,6718-4818-8011-6024,American Express\n",
      "39,Stockbroker,Leanne_Newton1268@typill.biz,Leanne Newton,5438-0816-4166-4847,American Express\n",
      "57,Budget Analyst,Tony_Giles1960@iatim.tech,Tony Giles,8130-3425-7573-7745,American Express\n",
      "62,CNC Operator,Owen_Allcott5125@bauros.biz,Owen Allcott,4156-0107-7210-2630,American Express\n",
      "68,Project Manager,Liam_Lynn3280@kideod.biz,Liam Lynn,7152-3247-6053-2233,American Express\n",
      "74,Dentist,Regina_Woodcock5820@yahoo.com,Regina Woodcock,0208-1753-3870-8002,American Express\n",
      "81,HR Specialist,Carter_Wallace9614@atink.com,Carter Wallace,4256-7201-6717-4322,American Express\n",
      "92,Staffing Consultant,Maia_Stark2797@jiman.org,Maia Stark,3851-1403-1734-6321,American Express\n",
      "97,Stockbroker,Ciara_Lomax982@bauros.biz,Ciara Lomax,3702-3440-2472-5424,American Express\n",
      "116,Staffing Consultant,Isabel_Ellwood1475@fuliss.net,Isabel Ellwood,3738-0882-0066-6683,American Express\n",
      "148,CNC Operator,Abdul_Townend2202@infotech44.tech,Abdul Townend,4224-1226-3557-3448,American Express\n",
      "150,Fabricator,Caleb_Poulton1735@atink.com,Caleb Poulton,8203-6875-5225-0341,American Express\n",
      "151,Restaurant Manager,Ronald_Lewis6777@deavo.com,Ronald Lewis,7212-0155-5014-8471,American Express\n",
      "154,Bellman,Faith_Seymour3829@twace.org,Faith Seymour,4170-5186-6887-6558,American Express\n",
      "169,Assistant Buyer,Anthony_Hancock9083@qater.org,Anthony Hancock,0832-3357-6010-6550,American Express\n",
      "176,Healthcare Specialist,Isabella_Willson5478@nanoff.biz,Isabella Willson,5177-4868-4623-0384,American Express\n",
      "182,Pharmacist,Stephanie_Darcy3298@bauros.biz,Stephanie Darcy,0264-4020-5106-5576,American Express\n",
      "199,Investment  Advisor,Ryan_Kennedy5565@corti.com,Ryan Kennedy,3166-6287-6242-7207,American Express\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "file_csv = \"user_data.csv\"\n",
    "data = json.load(open('user_data.json'))\n",
    "with open(\"user_data.csv\", mode = 'w') as outfile:\n",
    "    for i in data:\n",
    "        if i['CreditCardType'] == \"American Express\":\n",
    "           outfile.write(i[\"ID\"] + ',' + i[\"JobTitle\"] + ',' + i[\"EmailAddress\"] + ',' + \n",
    "            i[\"FirstNameLastName\"] + ',' + i[\"CreditCard\"] + ',' + i[\"CreditCardType\"] + \"\\n\")\n",
    "!type user_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Optional**: load the remote file:\n",
    "\n",
    "- https://www.dropbox.com/s/aamg1apjhclecka/regression_generated.csv\n",
    "\n",
    "with Pandas and create a scatter plot with all possible combinations of the following features:\n",
    "    \n",
    "  + features_1\n",
    "  + features_2\n",
    "  + features_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
